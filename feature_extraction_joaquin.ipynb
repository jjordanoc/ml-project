{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "nltk.download('cmudict')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NUEsSkdbrv14",
    "outputId": "23cde7dd-10f7-49cd-9fd5-7dc2db2a6908",
    "ExecuteTime": {
     "end_time": "2023-11-10T00:34:43.203615100Z",
     "start_time": "2023-11-10T00:34:41.798142300Z"
    }
   },
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cmudict to\n",
      "[nltk_data]     /home/jjordanoc/nltk_data...\n",
      "[nltk_data]   Package cmudict is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from nltk.corpus import cmudict\n",
    "d = cmudict.dict()"
   ],
   "metadata": {
    "id": "rXHmc_A_r579",
    "ExecuteTime": {
     "end_time": "2023-11-10T00:34:51.244336700Z",
     "start_time": "2023-11-10T00:34:50.273569200Z"
    }
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from faster_whisper import WhisperModel"
   ],
   "metadata": {
    "id": "nQpdAv1Fr306",
    "ExecuteTime": {
     "end_time": "2023-11-10T00:52:42.719329Z",
     "start_time": "2023-11-10T00:52:42.384666300Z"
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import regex as re"
   ],
   "metadata": {
    "id": "yFX-9Hu4sxEu",
    "ExecuteTime": {
     "end_time": "2023-11-10T00:34:51.839649700Z",
     "start_time": "2023-11-10T00:34:51.828008900Z"
    }
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Run on GPU with FP16\n",
    "model = WhisperModel(\"large-v2\", device=\"cuda\", compute_type=\"float16\", download_root=\"faster-whisper/\")"
   ],
   "metadata": {
    "id": "LUM4D-hdoctf",
    "ExecuteTime": {
     "end_time": "2023-11-10T00:54:03.381562800Z",
     "start_time": "2023-11-10T00:52:45.283771Z"
    }
   },
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading (…)37e8b/tokenizer.json:   0%|          | 0.00/2.20M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "089f2a543b7d471584f19f499bec76e3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)08837e8b/config.json:   0%|          | 0.00/2.80k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0f0528d2cc2c43a9a28114af31cac8a3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)37e8b/vocabulary.txt:   0%|          | 0.00/460k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6f00d0be036f4edd8e54e9aec109fdb9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading model.bin:   0%|          | 0.00/3.09G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "274cc66a9af9488fb0952b3fc18ec94c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m a, b \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241m.\u001B[39mtranscribe(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maudio-data/001 - Low/Avalinguo - Xoca and Josué segment 80 - J.mp3\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "a, b = model.transcribe(\"audio-data/001 - Low/Avalinguo - Xoca and Josué segment 80 - J.mp3\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-10T01:00:25.017132500Z",
     "start_time": "2023-11-10T01:00:24.738170900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a, b = model.transcribe(\"C:/Users/rojot/OneDrive/Escritorio/machine learning/repo/project/audio-data/001 - Low/Avalinguo - Xoca and Josué segment 80 - J.mp3\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def syllables_aux(word: str) -> int:\n",
    "    #referred from stackoverflow.com/questions/14541303/count-the-number-of-syllables-in-a-word\n",
    "    count = 0\n",
    "    vowels = 'aeiouy'\n",
    "    word = word.lower()\n",
    "    if(len(word)>0):\n",
    "        if word[0] in vowels:\n",
    "            count +=1\n",
    "        for index in range(1,len(word)):\n",
    "            if word[index] in vowels and word[index-1] not in vowels:\n",
    "                count +=1\n",
    "        if word.endswith('e'):\n",
    "            count -= 1\n",
    "        if word.endswith('le'):\n",
    "            count += 1\n",
    "        if count == 0:\n",
    "            count += 1\n",
    "    return count"
   ],
   "metadata": {
    "id": "S5PcUhXwrgfO",
    "ExecuteTime": {
     "end_time": "2023-11-10T00:35:23.269765Z",
     "start_time": "2023-11-10T00:35:23.161121200Z"
    }
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def count_word_syllables(word: str):\n",
    "    try:\n",
    "        # return the pronunciation with the minimum number of syllables\n",
    "        return min([len(list(y for y in x if y[-1].isdigit())) for x in d[word.lower()]])\n",
    "    except KeyError:\n",
    "        return syllables_aux(word)"
   ],
   "metadata": {
    "id": "7ruNkJVjqmyU",
    "ExecuteTime": {
     "end_time": "2023-11-10T00:28:45.879339800Z",
     "start_time": "2023-11-10T00:28:45.841628100Z"
    }
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_audio_duration(file_path: str):\n",
    "   audio_data, sample_rate = librosa.load(file_path)\n",
    "   duration = librosa.get_duration(y=audio_data, sr=sample_rate)\n",
    "   return duration"
   ],
   "metadata": {
    "id": "azc3fLY8szmz",
    "ExecuteTime": {
     "end_time": "2023-11-10T00:28:45.916796100Z",
     "start_time": "2023-11-10T00:28:45.883856500Z"
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def clean_word(word: str) -> str:\n",
    "    lower = word.lower()\n",
    "    new_str = \"\"\n",
    "    for c in lower:\n",
    "        if c.isalpha():\n",
    "            new_str += c\n",
    "    return new_str"
   ],
   "metadata": {
    "id": "WjyBOwY9ilGY",
    "ExecuteTime": {
     "end_time": "2023-11-10T00:28:45.940855600Z",
     "start_time": "2023-11-10T00:28:45.916796100Z"
    }
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def is_filler_word(word: str) -> str:\n",
    "    return re.fullmatch(r\"u+m+|e+m+|e+r+|e+h+|u+h+\", word) is not None"
   ],
   "metadata": {
    "id": "-b1JwCwKBu3R",
    "ExecuteTime": {
     "end_time": "2023-11-10T00:28:46.020350500Z",
     "start_time": "2023-11-10T00:28:45.989185Z"
    }
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def features_yu(audio_file: str) -> np.array:\n",
    "    \"\"\"\n",
    "    (1) articulation rate = number of syllables, including disfluencies, divided by to-\n",
    "    tal duration of speech apart from all (silent and filled) pauses longer than\n",
    "    0.25 seconds;\n",
    "    (2) speech rate = as for articulation rate, but including all pauses in the total\n",
    "    speech duration;\n",
    "    (3) effective speech rate = as for speech rate, but excluding disfluencies from the\n",
    "    syllable count;\n",
    "    (4) number of silent pauses above 0.25 seconds in duration;\n",
    "    (5) mean length of silent pauses longer than 0. 25 seconds;\n",
    "    (6) number of filled pauses (uh, er, mm, etc.);\n",
    "    (7) mean length of all filled pauses;\n",
    "    (8) number of pauses = sum of (4) and (6);\n",
    "    (9) mean length of pauses = mean of (5) and (7), weighted by their respective\n",
    "    frequencies (items 4 and 6);\n",
    "    (10) number of other disfluencies (repetitions, restarts, false starts, corrections);\n",
    "    (11) mean length of fluent runs = mean number of syllables produced between\n",
    "    silent pauses longer than 0.25 seconds;\n",
    "    (12) phonation/time ratio, calculated on the basis of items 4 and 6, as a percentage\n",
    "    of overall speech time = (total duration of speech without pauses, divided by\n",
    "    total duration of speech including pauses) × 100\n",
    "    \"\"\"\n",
    "    print(\"Heree\")\n",
    "    results, _ = model.transcribe(audio_file,\n",
    "                              language=\"en\", word_timestamps=True, beam_size=5)\n",
    "    # audio_duration = get_audio_duration(audio_file)\n",
    "    silent_pauses = []\n",
    "    filled_pauses = []\n",
    "    duration_of_speech_excluding_pauses = 0\n",
    "    fluent_runs_syllables = []\n",
    "    # n_segments = 0\n",
    "    last_segment = None\n",
    "    for segment in results:\n",
    "        # n_segments += 1\n",
    "        # assert n_segments <= 1\n",
    "        print(\"New segment\")\n",
    "        if last_segment is not None:\n",
    "            silent_pause = segment.words[0].start - last_segment.words[-1].end\n",
    "            if silent_pause > 0.25:\n",
    "                silent_pauses.append(silent_pause)\n",
    "        for i in range(len(segment.words)):\n",
    "            word = segment.words[i]\n",
    "            print(\"[%.2fs -> %.2fs] %s\" % (word.start, word.end, word.word))\n",
    "            # Compute silent pauses\n",
    "            if i <= len(segment.words) - 2:\n",
    "                next = segment.words[i+1]\n",
    "                silent_pause = next.start - word.end\n",
    "                if silent_pause > 0.25:\n",
    "                    silent_pauses.append(silent_pause)\n",
    "            clean = clean_word(word.word)\n",
    "            # Compute filled pauses\n",
    "            if is_filler_word(clean):\n",
    "                filled_pauses.append(word.end - word.start)\n",
    "            else:\n",
    "                fluent_runs_syllables.append(count_word_syllables(clean))\n",
    "                duration_of_speech_excluding_pauses += word.end - word.start\n",
    "        last_segment = segment\n",
    "\n",
    "    articulation_rate = (sum(fluent_runs_syllables) + len(filled_pauses)) / duration_of_speech_excluding_pauses if duration_of_speech_excluding_pauses else 0\n",
    "    speech_rate = (sum(fluent_runs_syllables) + len(filled_pauses)) / (duration_of_speech_excluding_pauses + sum(filled_pauses) + sum(silent_pauses))\n",
    "    effective_speech_rate = sum(fluent_runs_syllables) / duration_of_speech_excluding_pauses if duration_of_speech_excluding_pauses else 0\n",
    "    number_of_silent_pauses = len(silent_pauses)\n",
    "    mean_length_of_silent_pauses = sum(silent_pauses) / number_of_silent_pauses if number_of_silent_pauses else 0\n",
    "    number_of_filled_pauses = len(filled_pauses)\n",
    "    mean_length_of_filled_pauses = sum(filled_pauses) / number_of_filled_pauses if number_of_filled_pauses else 0\n",
    "    number_of_pauses = number_of_silent_pauses + number_of_filled_pauses\n",
    "    mean_length_of_pauses = (mean_length_of_silent_pauses * number_of_silent_pauses + mean_length_of_filled_pauses * number_of_filled_pauses) / number_of_pauses if number_of_pauses else 0\n",
    "    number_of_other_disfluencies = 0 # TODO\n",
    "    mean_length_of_fluent_runs = sum(fluent_runs_syllables) / len(fluent_runs_syllables) if len(fluent_runs_syllables) else 0\n",
    "    phonation_ratio = duration_of_speech_excluding_pauses / (duration_of_speech_excluding_pauses + sum(filled_pauses) + sum(silent_pauses))\n",
    "    return np.array([\n",
    "        articulation_rate,\n",
    "        speech_rate,\n",
    "        effective_speech_rate,\n",
    "        number_of_silent_pauses,\n",
    "        mean_length_of_silent_pauses,\n",
    "        number_of_filled_pauses,\n",
    "        mean_length_of_filled_pauses,\n",
    "        number_of_pauses,\n",
    "        mean_length_of_pauses,\n",
    "        number_of_other_disfluencies,\n",
    "        mean_length_of_fluent_runs,\n",
    "        phonation_ratio\n",
    "    ])"
   ],
   "metadata": {
    "id": "HlKiJC3sExE6",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "outputId": "74f64669-6032-492d-c864-f3bceb95113e",
    "ExecuteTime": {
     "end_time": "2023-11-10T00:41:41.448240600Z",
     "start_time": "2023-11-10T00:41:41.378089Z"
    }
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "features_yu(\"audio-data/001 - Low/Avalinguo - Xoca and Josué segment 80 - J.mp3\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "LPZYQrllK2U_",
    "outputId": "c72401e3-8ec0-4505-88ce-02c4812b7de9",
    "ExecuteTime": {
     "end_time": "2023-11-10T00:42:09.759459700Z",
     "start_time": "2023-11-10T00:42:09.602152900Z"
    }
   },
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features_yu' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mfeatures_yu\u001B[49m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maudio-data/001 - Low/Avalinguo - Xoca and Josué segment 80 - J.mp3\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'features_yu' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extract features and save to file"
   ],
   "metadata": {
    "id": "JX7yiuJwMmyy"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "PATH = \"audio-data/\""
   ],
   "metadata": {
    "id": "lOwp2v6nO7pT",
    "ExecuteTime": {
     "end_time": "2023-11-10T00:24:12.906553600Z",
     "start_time": "2023-11-10T00:24:12.886267Z"
    }
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "N_FEATURES_YU = 12"
   ],
   "metadata": {
    "id": "bsqqvD6WOrND",
    "ExecuteTime": {
     "end_time": "2023-11-10T00:24:13.233689700Z",
     "start_time": "2023-11-10T00:24:13.221606300Z"
    }
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "audio_subdirectories = os.listdir(PATH)\n",
    "audio_subdirectories.sort()\n",
    "print('Audio Subdirs: ', audio_subdirectories)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-NECkH1XNj9e",
    "outputId": "c2ac9a41-9e36-4f65-e070-553177b0566a",
    "ExecuteTime": {
     "end_time": "2023-11-10T00:24:13.611495300Z",
     "start_time": "2023-11-10T00:24:13.523052600Z"
    }
   },
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio Subdirs:  ['001 - Low', '002 - Intermediate', '003 - High']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def parse_audio_files(parent_dir, sub_dirs, file_ext='*.mp3'): # Audio Format\n",
    "    features = np.empty((0, N_FEATURES_YU))\n",
    "    labels = np.empty(0, dtype=np.int)\n",
    "    for label, sub_dir in enumerate(sub_dirs):\n",
    "        for file_name in glob.glob(os.path.join(parent_dir, sub_dir, file_ext)):\n",
    "            print(\"Actual File Name: \", file_name)\n",
    "            try:\n",
    "                extracted_features = features_yu(file_name)\n",
    "            except Exception as e:\n",
    "                print(\"[Error] there was an error in feature extraction. %s\" % (e))\n",
    "                continue\n",
    "            print(\"Features: \", extracted_features)\n",
    "            features = np.vstack([features, extracted_features])\n",
    "            labels = np.append(labels, label)\n",
    "        print(\"Extracted features from %s, done\" % (sub_dir))\n",
    "    return features, labels"
   ],
   "metadata": {
    "id": "J9BJQxE1Mp3P"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "features, labels = parse_audio_files(PATH, audio_subdirectories) #(parent dir,sub dirs)\n",
    "np.save('feat.npy', features)\n",
    "np.save('label.npy', labels)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "KxlXV0UfOIlc",
    "outputId": "bf08e179-57f4-4568-9a37-bec9e31c6699"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-30-da1dc1e3a2f1>:3: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  labels = np.empty(0, dtype=np.int)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Actual File Name:  /content/drive/MyDrive/Proyecto ML/audio_data/001 - Low/Interview with a Filippines Woman segment 22 - W.mp3\n",
      "Features:  [3.97350993 3.26086957 3.97350993 1.         0.66       0.\n",
      " 0.         1.         0.66       0.         1.5        0.82065217]\n",
      "Actual File Name:  /content/drive/MyDrive/Proyecto ML/audio_data/001 - Low/Avalinguo - Victor and Abraham segment 131.mp3\n",
      "Features:  [6.52173913 6.52173913 6.52173913 0.         0.         0.\n",
      " 0.         0.         0.         0.         1.5        1.        ]\n",
      "Actual File Name:  /content/drive/MyDrive/Proyecto ML/audio_data/001 - Low/Avalinguo - Victor and Abraham segment 119.mp3\n",
      "Features:  [3.57142857 3.57142857 3.57142857 0.         0.         0.\n",
      " 0.         0.         0.         0.         1.15384615 1.        ]\n",
      "Actual File Name:  /content/drive/MyDrive/Proyecto ML/audio_data/001 - Low/Avalinguo - Dana and Konay segment 4 - D.mp3\n",
      "Features:  [2.80373832 1.80722892 2.80373832 1.         1.18       0.\n",
      " 0.         1.         1.18       0.         1.2        0.64457831]\n",
      "Actual File Name:  /content/drive/MyDrive/Proyecto ML/audio_data/001 - Low/Avalinguo - Victor and Abraham segment 11.mp3\n",
      "Features:  [3.15789474 3.15789474 3.15789474 0.         0.         0.\n",
      " 0.         0.         0.         0.         2.         1.        ]\n",
      "Actual File Name:  /content/drive/MyDrive/Proyecto ML/audio_data/001 - Low/Avalinguo - Victor and Abraham segment 39.mp3\n",
      "Features:  [3.93258427 2.90456432 3.93258427 2.         0.63       0.\n",
      " 0.         2.         0.63       0.         1.27272727 0.73858921]\n",
      "Actual File Name:  /content/drive/MyDrive/Proyecto ML/audio_data/001 - Low/Avalinguo - Victor and Abraham segment 125.mp3\n",
      "Features:  [2.33160622 2.33160622 2.33160622 0.         0.         0.\n",
      " 0.         0.         0.         0.         1.28571429 1.        ]\n",
      "Actual File Name:  /content/drive/MyDrive/Proyecto ML/audio_data/001 - Low/Interview with a Filippines Woman segment 50 - W.mp3\n",
      "Features:  [3.96825397 2.92397661 3.96825397 1.         0.9        0.\n",
      " 0.         1.         0.9        0.         1.42857143 0.73684211]\n",
      "Actual File Name:  /content/drive/MyDrive/Proyecto ML/audio_data/001 - Low/Avalinguo - Dana and Konay segment 119 - D.mp3\n",
      "Features:  [1.44628099 1.44628099 1.44628099 0.         0.         0.\n",
      " 0.         0.         0.         0.         1.16666667 1.        ]\n",
      "Actual File Name:  /content/drive/MyDrive/Proyecto ML/audio_data/001 - Low/Avalinguo - Xoca and Josué segment 74 - J.mp3\n",
      "[Error] there was an error in feature extraction. \n",
      "Actual File Name:  /content/drive/MyDrive/Proyecto ML/audio_data/001 - Low/Avalinguo - Itzel and Friend segment 6 - I.mp3\n",
      "Features:  [2.77777778 2.77777778 2.77777778 0.         0.         0.\n",
      " 0.         0.         0.         0.         3.         1.        ]\n",
      "Actual File Name:  /content/drive/MyDrive/Proyecto ML/audio_data/001 - Low/Avalinguo - Dana and Konay segment 36 - D.mp3\n",
      "Features:  [2.39520958 1.6064257  2.39520958 2.         0.82       0.\n",
      " 0.         2.         0.82       0.         1.14285714 0.67068273]\n",
      "Actual File Name:  /content/drive/MyDrive/Proyecto ML/audio_data/001 - Low/Avalinguo - Dana and Konay segment 26 - D.mp3\n",
      "Features:  [3.40136054 2.10084034 3.40136054 1.         1.82       0.\n",
      " 0.         1.         1.82       0.         1.25       0.61764706]\n",
      "Actual File Name:  /content/drive/MyDrive/Proyecto ML/audio_data/001 - Low/Avalinguo - Itzel and Friend segment 45 - I.mp3\n",
      "Features:  [2.01612903 2.01612903 2.01612903 0.         0.         0.\n",
      " 0.         0.         0.         0.         1.25       1.        ]\n",
      "Actual File Name:  /content/drive/MyDrive/Proyecto ML/audio_data/001 - Low/Avalinguo - Victor and Abraham segment 38.mp3\n",
      "Features:  [2.21774194 2.21774194 2.21774194 0.         0.         0.\n",
      " 0.         0.         0.         0.         1.1        1.        ]\n",
      "Actual File Name:  /content/drive/MyDrive/Proyecto ML/audio_data/001 - Low/Avalinguo - Xoca and Josué segment 90 - J.mp3\n",
      "Features:  [2.08333333 1.1627907  2.08333333 2.         0.95       0.\n",
      " 0.         2.         0.95       0.         1.66666667 0.55813953]\n",
      "Actual File Name:  /content/drive/MyDrive/Proyecto ML/audio_data/001 - Low/Avalinguo - Itzel and Friend segment 55 - I.mp3\n",
      "Features:  [0.80321285 0.80321285 0.80321285 0.         0.         0.\n",
      " 0.         0.         0.         0.         1.33333333 1.        ]\n",
      "Actual File Name:  /content/drive/MyDrive/Proyecto ML/audio_data/001 - Low/Avalinguo - Xoca and Josué segment 80 - J.mp3\n",
      "[Error] there was an error in feature extraction. \n",
      "Actual File Name:  /content/drive/MyDrive/Proyecto ML/audio_data/001 - Low/Avalinguo - Xoca and Josué segment 29 - J.mp3\n",
      "Features:  [2.8125     2.06422018 2.8125     2.         0.58       0.\n",
      " 0.         2.         0.58       0.         1.         0.73394495]\n",
      "Actual File Name:  /content/drive/MyDrive/Proyecto ML/audio_data/001 - Low/Avalinguo - Victor and Abraham segment 10.mp3\n",
      "[Error] there was an error in feature extraction. \n",
      "Actual File Name:  /content/drive/MyDrive/Proyecto ML/audio_data/001 - Low/Avalinguo - Xoca and Josué segment 3 - J.mp3\n",
      "[Error] there was an error in feature extraction. \n",
      "Actual File Name:  /content/drive/MyDrive/Proyecto ML/audio_data/001 - Low/Elderly Chinese street cleaner speaks fluent English segment 53 - E.mp3\n",
      "[Error] there was an error in feature extraction. \n",
      "Actual File Name:  /content/drive/MyDrive/Proyecto ML/audio_data/001 - Low/Elderly Chinese street cleaner speaks fluent English segment 21 - E.mp3\n",
      "Features:  [3.61111111 3.61111111 3.61111111 0.         0.         0.\n",
      " 0.         0.         0.         0.         1.3        1.        ]\n",
      "Actual File Name:  /content/drive/MyDrive/Proyecto ML/audio_data/001 - Low/Avalinguo - Xoca and Josué segment 100 - J.mp3\n",
      "Features:  [2.74725275 2.74725275 2.74725275 0.         0.         0.\n",
      " 0.         0.         0.         0.         1.25       1.        ]\n",
      "Actual File Name:  /content/drive/MyDrive/Proyecto ML/audio_data/001 - Low/Avalinguo - Xoca and Josué segment 110 - J.mp3\n",
      "Features:  [1.02040816 1.02040816 1.02040816 0.         0.         0.\n",
      " 0.         0.         0.         0.         1.         1.        ]\n",
      "Actual File Name:  /content/drive/MyDrive/Proyecto ML/audio_data/001 - Low/Avalinguo - Itzel and Friend segment 18 - I.mp3\n",
      "Features:  [2.67857143 1.71428571 2.67857143 1.         1.26       0.\n",
      " 0.         1.         1.26       0.         1.2        0.64      ]\n",
      "Actual File Name:  /content/drive/MyDrive/Proyecto ML/audio_data/001 - Low/Elderly Chinese street cleaner speaks fluent English segment 31 - E.mp3\n",
      "Features:  [2.09302326 1.80722892 2.09302326 1.         0.68       0.\n",
      " 0.         1.         0.68       0.         1.28571429 0.86345382]\n",
      "Actual File Name:  /content/drive/MyDrive/Proyecto ML/audio_data/001 - Low/Avalinguo - Victor and Abraham segment 124.mp3\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-31-9d666fad547d>\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mfeatures\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mparse_audio_files\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mPATH\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maudio_subdirectories\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;31m#(parent dir,sub dirs)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'feat.npy'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfeatures\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'label.npy'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-30-da1dc1e3a2f1>\u001B[0m in \u001B[0;36mparse_audio_files\u001B[0;34m(parent_dir, sub_dirs, file_ext)\u001B[0m\n\u001B[1;32m      6\u001B[0m             \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Actual File Name: \"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfile_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m                 \u001B[0mextracted_features\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfeatures_yu\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfile_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      9\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m                 \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"[Error] there was an error in feature extraction. %s\"\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-28-107bb9393b13>\u001B[0m in \u001B[0;36mfeatures_yu\u001B[0;34m(audio_file)\u001B[0m\n\u001B[1;32m     22\u001B[0m     total duration of speech including pauses) × 100\n\u001B[1;32m     23\u001B[0m     \"\"\"\n\u001B[0;32m---> 24\u001B[0;31m     results, _ = model.transcribe(audio_file,\n\u001B[0m\u001B[1;32m     25\u001B[0m                               language=\"en\", word_timestamps=True, beam_size=5)\n\u001B[1;32m     26\u001B[0m     \u001B[0maudio_duration\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_audio_duration\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0maudio_file\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/faster_whisper/transcribe.py\u001B[0m in \u001B[0;36mtranscribe\u001B[0;34m(self, audio, language, task, beam_size, best_of, patience, length_penalty, repetition_penalty, no_repeat_ngram_size, temperature, compression_ratio_threshold, log_prob_threshold, no_speech_threshold, condition_on_previous_text, prompt_reset_on_temperature, initial_prompt, prefix, suppress_blank, suppress_tokens, without_timestamps, max_initial_timestamp, word_timestamps, prepend_punctuations, append_punctuations, vad_filter, vad_parameters)\u001B[0m\n\u001B[1;32m    256\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    257\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0maudio\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndarray\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 258\u001B[0;31m             \u001B[0maudio\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdecode_audio\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0maudio\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msampling_rate\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msampling_rate\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    259\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    260\u001B[0m         \u001B[0mduration\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0maudio\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m/\u001B[0m \u001B[0msampling_rate\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/faster_whisper/audio.py\u001B[0m in \u001B[0;36mdecode_audio\u001B[0;34m(input_file, sampling_rate, split_stereo)\u001B[0m\n\u001B[1;32m     58\u001B[0m     \u001B[0;31m# unless the garbage collector is manually run.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     59\u001B[0m     \u001B[0;32mdel\u001B[0m \u001B[0mresampler\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 60\u001B[0;31m     \u001B[0mgc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcollect\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     61\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m     \u001B[0maudio\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrombuffer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mraw_buffer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgetbuffer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Keep alive"
   ],
   "metadata": {
    "id": "LeDteAXCujtX"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import time\n",
    "while True:\n",
    "    print(\"Keep alive\")\n",
    "    time.sleep(30)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "id": "lc32qb-Nuka8",
    "outputId": "fe082ec2-cd10-4ba4-9fe3-94d975629ea3"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Keep alive\n",
      "Keep alive\n",
      "Keep alive\n",
      "Keep alive\n",
      "Keep alive\n",
      "Keep alive\n",
      "Keep alive\n",
      "Keep alive\n",
      "Keep alive\n",
      "Keep alive\n",
      "Keep alive\n",
      "Keep alive\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-8-90aa1e90f11d>\u001B[0m in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;32mwhile\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Keep alive\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m     \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msleep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m30\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  }
 ]
}
